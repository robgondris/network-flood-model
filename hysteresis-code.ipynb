{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hysteresis Model Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for the hysteresis model. In this notebook, as an example it's being run on the full network with no dams for the duration of storm Ciara. I make use of the @jit decorator from numba, which compiles code in order to allow it to run at speeds approaching a much faster language like C. This does not however support pandas, meaning a lot of the functions are defined by looping over numpy arrays. This is the efficient approach though, as a numerical IVP solver for this problem will need to evaluate the same functions many times, and compiling these functions will greatly reduce computational cost. <br> The imports and data needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports:\n",
    "import math\n",
    "import pickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "from datetime import datetime\n",
    "from scipy.optimize import root\n",
    "from scipy.integrate import solve_ivp\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "\n",
    "\n",
    "# data - note terrain data is in a shapefile so need geopandas to unpack it\n",
    "terrain = gpd.read_file('data/terrain/terrain.shp')\n",
    "# set coordinate system\n",
    "terrain.crs = {'init': 'espg3857'}\n",
    "\n",
    "rain = pd.read_csv('data/edited_rain.csv', header=0, parse_dates=[0], index_col=0)  #inflow data\n",
    "check = pd.read_csv('data/bowston_gauge_data.csv', header=0)  #Bowston gauge data, to check results against\n",
    "\n",
    "widths = np.load(open('data/widths.npy','rb'))  #segment widths from checking-data.ipynb\n",
    "\n",
    "# indexing correctly\n",
    "check['datetime'] = pd.to_datetime(check['datetime'], dayfirst = True)\n",
    "check = check.set_index('datetime')\n",
    "rain.columns = [int(x)-1 for x in rain.columns]  #correcting column index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code solves the following system of differential equations, where $\\epsilon$ is chosen to be small. For details see the writeup.\n",
    "$$\n",
    "\\epsilon\\frac{d\\mathbf{h}}{dt} = \\mathbf{V} - \\mathbf{\\tilde{V}}(\\mathbf{h})\n",
    "$$\n",
    "$$\n",
    "\\frac{d\\mathbf{V}}{dt} = A^\\mathsf{T}\\mathbf{\\tilde{Q}(\\mathbf{h})} - \\mathbf{\\tilde{Q}(\\mathbf{h})} + \\mathbf{q}(t)\n",
    "$$\n",
    "There are various imputs for the model, specifically determining the placement of dams and their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "manning = 0.03\n",
    "\n",
    "\n",
    "N = terrain.shape[0]\n",
    "cat_lambda = 10 * np.ones(N)\n",
    "\n",
    "Adj = np.zeros((N,N)) #adjacency matrix\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        if terrain['TONODE'][i] == terrain['FROMNODE'][j]:\n",
    "            Adj[i,j]=1\n",
    "\n",
    "dams = []\n",
    "dams = []  #Index for segments to have dams. no dams for this example run\n",
    "lower_heights = []  #specifics of each dam. Must be same length as dams\n",
    "upper_heights = []\n",
    "kvals = []  #permeabilities - assumed to be 0 for each dam \n",
    "\n",
    "# timeframe of interest - this is for storm Ciara\n",
    "start = pd.to_datetime('2020-02-08 6pm')\n",
    "end = pd.to_datetime('2020-02-10 6pm')\n",
    "eval_no = 100  #no. of points to evaluate solution at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General data handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_df=terrain[['Shape_Leng','Slope']]\n",
    "data_df.columns = ['l', 'S']\n",
    "data_df['S'] = data_df['S'].apply(lambda x: x*-1)\n",
    "data_df.loc[data_df.S<=0.01, 'S'] = 0.01\n",
    "\n",
    "data_df['w']=widths\n",
    "data_df['h_l']=100*np.ones(N)\n",
    "data_df['h_u']=101*np.ones(N)\n",
    "data_df['k']=np.zeros(N)\n",
    "\n",
    "for i, dam in enumerate(dams):\n",
    "    data_df.k[dam] = kvals[i]\n",
    "    data_df.h_l[dam] = lower_heights[i]\n",
    "    data_df.h_u[dam] = upper_heights[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a function to get rain values at a time $t$ seconds after the start of the interval of interest. Note that the rain function is dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = check[start:end]\n",
    "rain = rain[start:end]\n",
    "rainvals = rain.to_numpy()\n",
    "\n",
    "@jit(nopython=True)\n",
    "def rainfun(t):\n",
    "    minutes = t/60\n",
    "    # find number of 5 minute intervals that have passed:\n",
    "    i = int((minutes - (minutes%15))/15)\n",
    "    return rainvals[i,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nondimensionalising - see writeup for details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "manning = 0.035\n",
    "cst_w, cst_h, cst_S, cst_g, cst_l = 2., 1, 0.05, 9.8, 100.\n",
    "cst_Q = cst_w*cst_h**(5/3)*cst_S**(1/2) / manning\n",
    "cst_t = cst_l*cst_w*cst_h/cst_Q\n",
    "cst_V = cst_l*cst_w*cst_h\n",
    "cst_alpha = cst_h / cst_w\n",
    "cst_gamma = math.sqrt(2*cst_g) * cst_h**(3/2) * cst_w / cst_Q\n",
    "cst_beta = cst_h / (cst_S*cst_l)\n",
    "\n",
    "# putting everything into a dataframe\n",
    "df = pd.DataFrame()\n",
    "df['l'] = data_df['l']/cst_l\n",
    "df['S'] = data_df['S']/cst_S\n",
    "df['w'] = data_df['w']/cst_w\n",
    "df['h_l'] = data_df['h_l']/cst_h\n",
    "df['h_u'] = data_df['h_u']/cst_h\n",
    "df['k'] = data_df['k']\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "#immediately leave pandas for compatibility with numba.jit :(\n",
    "l = tuple(df.l.tolist())\n",
    "S = tuple(df.S.tolist())\n",
    "w = tuple(df.w.tolist())\n",
    "h_l = tuple(df.h_l.tolist())\n",
    "h_u = tuple(df.h_u.tolist())\n",
    "k = tuple(df.k.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the normalised flow function $\\mathbf{\\tilde{Q}(\\mathbf{h})}$. First, the critical values $h_c$ have to be calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define qfric and qdam\n",
    "def Qfric1(h, i):\n",
    "    Qf = w[i]*h**(5/3) * math.sqrt(S[i])\n",
    "    return Qf\n",
    "\n",
    "def Qdam1(h, i):\n",
    "    a1 = h_l[i]*h / np.sqrt(h+h_l[i])\n",
    "    a2 = k[i] * np.sqrt(h) * min( h-h_l[i], h_u[i]-h_l[i] )\n",
    "    a3 = 2/3 * max(0, h-h_u[i])**(3/2)\n",
    "    Qd = cst_gamma * w[i] * (a1+a2+a3)\n",
    "    return  Qd\n",
    "\n",
    "\n",
    "# find hstar values by using scipy's root solver.\n",
    "# Here, finding the difference by finding roots of fun(z).\n",
    "\n",
    "hcrit=[]\n",
    "for i in range(N):\n",
    "    def fun(z):\n",
    "        fric = Qfric1(z, i)\n",
    "        dam = Qdam1(z, i)\n",
    "        return fric-dam\n",
    "    hcrit.append(root(fun, h_u[i]).x[0])\n",
    "hcrit = tuple(hcrit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining $\\mathbf{\\tilde{Q}(\\mathbf{h})}$ and $\\mathbf{\\tilde{V}(\\mathbf{h})}$ properly. Note these are not vector valued functions, instead are a family of functions indexed by segment number $i$. See writeup for explanation of functions used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def Qfric(h, i):\n",
    "    Qf = w[i]*h**(5/3) * math.sqrt(S[i])\n",
    "    return Qf\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def Qdam(h, i):\n",
    "    a1 = h_l[i]*h / np.sqrt(h+h_l[i])\n",
    "    a2 = k[i] * np.sqrt(h) * min( h-h_l[i], h_u[i]-h_l[i] )\n",
    "    a3 = 0.6*2/3 * max(0, h-h_u[i])**(3/2)\n",
    "    Qd = cst_gamma * w[i] * (a1+a2+a3)\n",
    "    return  Qd\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def Qfun(h, i):\n",
    "    if h<max(hcrit[i], h_l[i]):\n",
    "        return Qfric(h, i)\n",
    "    else:\n",
    "        return Qdam(h, i)\n",
    "\n",
    "@jit(nopython=True)        \n",
    "def Vfun(h, i):\n",
    "    hstr = (Qfun(h,i) /w[i] /np.sqrt(S[i]))**(3/5)  #downstream flow\n",
    "    if h < hstr + S[i]*l[i]/cst_beta:\n",
    "        return w[i]*l[i]*hstr + cst_lambda[i]*0.5*cst_beta*w[i]* max(0, h-hstr)**2 / S[i]\n",
    "    else:\n",
    "        return w[i]*l[i]*( h - S[i]*l[i]/cst_beta + cst_lambda[i]/2*S[i]*l[i]/cst_beta)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the derivative $D$ at a point. Note this is a derivative for both $\\mathbf{h}$ and $\\mathbf{V}$. Note, here $\\epsilon = 0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def fun(h, V, q):\n",
    "    Q = np.zeros((N,1))\n",
    "    for i in range(N):\n",
    "        Q[i,0] = Qfun(h[i],i)\n",
    "    # dh/dt\n",
    "    D1 = [ 10*(V[i] - Vfun(h[i],i)) for i in range(N) ] \n",
    "    # dV/dt\n",
    "    D2 = Adj.T.dot(Q) - Q  + q\n",
    "    D2 = list(D2.flat)\n",
    "    return D1 + D2\n",
    "\n",
    "@jit(nopython=True)\n",
    "def derivative(t, X):\n",
    "    #unpacking\n",
    "    h = X[:N]\n",
    "    V = X[N:]\n",
    "    q = np.zeros((N,1))\n",
    "    q[:,0] = rainfun(t*cst_t)/cst_Q\n",
    "    return fun(h, V, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the problem, I am using scipy's standard IVP solver. As this can be a stiff problem ($\\mathbf{h}$ varies on a smaller timescale than $\\mathbf{V}$), I'm using an implicit solver designed for stiff problems. To get suitable initial conditions, I'm running it at a baseline for a short time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final time is 11039.787043198961\n",
      "The total time taken is 10779.229582 seconds.\n"
     ]
    }
   ],
   "source": [
    "T = (end-start).total_seconds() / cst_t\n",
    "\n",
    "def derivative2(t,X):\n",
    "    return derivative(0,X)\n",
    "\n",
    "initial = [0]*(2*N)\n",
    "sol = solve_ivp(derivative2, (0,60*60/cst_t), initial, atol=1e-2, rtol=1e-2)\n",
    "initial = sol.y[:,-1]\n",
    "\n",
    "\n",
    "T = (end-start).total_seconds() / cst_t\n",
    "startTime = datetime.now()\n",
    "print('Final time is '+str(T))\n",
    "sol = solve_ivp(derivative, (0,T), initial, t_eval=np.linspace(0,T,eval_no) , atol=1e-3, rtol=1e-3, method='RK23')\n",
    "print('The total time taken is ' + str((datetime.now()-startTime).total_seconds())+' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most useful output are flow values. These can be calculated from Qfun defined above. I'm saving the flow values to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply Q(h) to the array of h values\n",
    "qoutput = pd.DataFrame(sol.y[:N].T, index=pd.date_range(start, end, 100))  #h solution values    \n",
    "\n",
    "for i, col in enumerate(qoutput.columns):\n",
    "    qoutput[col] = qoutput[col].apply(lambda x: Qfun(x, i)*cst_Q)  #note renormalisation\n",
    "qoutput.to_csv('data/hysterisis_flow_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
