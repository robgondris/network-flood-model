{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Model Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for the numerical approximation model. In this notebook, as an example it's being run on the full network with no dams for the duration of storm Ciara. I make use of the @jit decorator from numba, which compiles code in order to allow it to run at speeds approaching a much faster language like C. This does not however support pandas, meaning a lot of the functions are defined by looping over numpy arrays. This is the efficient approach though, as a numerical IVP solver for this problem will need to evaluate the same functions many times, and compiling these functions will greatly reduce computational cost. <br> The imports and data needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n",
    "from datetime import datetime\n",
    "from scipy.optimize import root\n",
    "from scipy.integrate import solve_ivp\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "# data - note terrain data is in a shapefile so need geopandas to unpack it\n",
    "terrain = gpd.read_file('data/terrain/terrain.shp')\n",
    "# set coordinate system\n",
    "terrain.crs = {'init': 'espg3857'}\n",
    "\n",
    "rain = pd.read_csv('data/edited_rain.csv', header=0, parse_dates=[0], index_col=0)  #inflow data\n",
    "check = pd.read_csv('data/bowston_gauge_data.csv', header=0)  #Bowston gauge data, to check results against\n",
    "\n",
    "widths = np.load(open('data/widths.npy','rb'))  #segment widths from checking-data.ipynb\n",
    "\n",
    "# indexing correctly\n",
    "check['datetime'] = pd.to_datetime(check['datetime'], dayfirst = True)\n",
    "check = check.set_index('datetime')\n",
    "rain.columns = [int(x)-1 for x in rain.columns]  #correcting column index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code solves the following differential equations. For details see the writeup.\n",
    "\n",
    "$$\n",
    "\\frac{d\\mathbf{V}}{dt} = A^\\mathsf{T}\\mathbf{\\tilde{Q}(\\mathbf{h})} - \\mathbf{\\tilde{Q}(\\mathbf{h})} + \\mathbf{q}(t)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pot_dams = np.load(open('data/pot_dams.npy','rb'))\n",
    "# choose 100 dams at random\n",
    "pot_ind = [i for i, x in enumerate(pot_dams) if x]\n",
    "\n",
    "random.seed(0)  #makes random selection consistent through runs\n",
    "dams = np.sort(random.sample(pot_ind, 100))\n",
    "lower_heights = 0.3*np.ones(100)  #specifics of each dam. Must be same length as dams\n",
    "upper_heights = 2*np.ones(100)\n",
    "lambda_val = 10  #volume parameter, measures how much more volume each dam can store.\n",
    "kvals = np.zeros(100)  #permeabilities - assumed to be 0 for each dam \n",
    "\n",
    "\n",
    "# timeframe of interest - this is for storm Ciara\n",
    "start = pd.to_datetime('2020-02-08 6pm')\n",
    "end = pd.to_datetime('2020-02-10 6pm')\n",
    "eval_no = 100  #no. of points to evaluate solution at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General data handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = terrain.shape[0]\n",
    "Adj = np.zeros((N,N))  #adjacency matrix\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        if terrain['TONODE'][i] == terrain['FROMNODE'][j]:\n",
    "            Adj[i,j]=1 \n",
    "\n",
    "# getting the relevant data\n",
    "data_df=terrain[['Shape_Leng','Slope']]\n",
    "data_df.columns = ['l', 'S']\n",
    "data_df['S'] = data_df['S'].apply(lambda x: x*-1)\n",
    "data_df.loc[data_df.S<=0.1, 'S'] = 0.1\n",
    "\n",
    "# set all dams to be large enough to have no impact on any realistic flow\n",
    "data_df['w']=widths\n",
    "data_df['h_l']=100*np.ones(N)  #h_l is lower dam height, h_u upper\n",
    "data_df['h_u']=101*np.ones(N)\n",
    "data_df['k']=np.zeros(N)\n",
    "\n",
    "# change the required dam parameters to their correct values\n",
    "for i, dam in enumerate(dams):\n",
    "    data_df.k[dam] = kvals[i]\n",
    "    data_df.h_l[dam] = lower_heights[i]\n",
    "    data_df.h_u[dam] = upper_heights[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a function to get rain values at a time $t$ seconds after the start of the interval of interest. Note that the rain function is dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain = rain[start:end]\n",
    "rainvals = rain.to_numpy()\n",
    "check = check[start:end]\n",
    "\n",
    "@jit(nopython=True)\n",
    "def rainfun(t):\n",
    "    # redimensionalise time\n",
    "    minutes = t/60\n",
    "    # find number of 15 minute intervals that have passed:\n",
    "    i = int((minutes - (minutes%15))/15)\n",
    "    return rainvals[i,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nondimensionalising - see writeup for details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants:\n",
    "manning = 0.03  #typical manning constant\n",
    "cst_w, cst_h, cst_S, cst_g, cst_l = 2., 1., 0.05, 9.8, 100.\n",
    "cst_Q = cst_w*cst_h**(5/3)*cst_S**(1/2) / manning\n",
    "cst_t = cst_l*cst_w*cst_h/cst_Q\n",
    "cst_V = cst_l*cst_w*cst_h\n",
    "cst_alpha = cst_h / cst_w\n",
    "cst_gamma = np.sqrt(2*cst_g) * cst_h**(3/2) * cst_w / cst_Q\n",
    "cst_beta = cst_h / (cst_S*cst_l)\n",
    "cst_lambda = lambda_val*np.ones(N)\n",
    "\n",
    "# putting everything into a central normalised dataframe:\n",
    "df = pd.DataFrame()\n",
    "df['l'] = data_df['l']/cst_l\n",
    "df['S'] = data_df['S']/cst_S\n",
    "df['w'] = data_df['w']/cst_w\n",
    "df['h_l'] = data_df['h_l']/cst_h\n",
    "df['h_u'] = data_df['h_u']/cst_h\n",
    "df['k'] = data_df['k']  #k is a nondimensional constant\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "#immediately leave pandas for compatibility with numba.jit :(\n",
    "l = tuple(df.l.tolist())\n",
    "S = tuple(df.S.tolist())\n",
    "w = tuple(df.w.tolist())\n",
    "h_l = tuple(df.h_l.tolist())\n",
    "h_u = tuple(df.h_u.tolist())\n",
    "k = tuple(df.k.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the normalised flow function $\\mathbf{\\tilde{Q}(\\mathbf{h})}$. First, the critical values $h_c$ have to be calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Qfric and Qdam\n",
    "def Qfric(h, i):\n",
    "    Qf = w[i]*h**(5/3) * np.sqrt(S[i])\n",
    "    return Qf\n",
    "\n",
    "def Qdam(h, i):\n",
    "    a1 = h_l[i]*h / np.sqrt(h+h_l[i])\n",
    "    a2 = k[i] * np.sqrt(h) * min( h-h_l[i], h_u[i]-h_l[i] )\n",
    "    a3 = 0.6*2/3 * max(0, h-h_u[i])**(3/2)\n",
    "    Qd = cst_gamma * w[i] * (a1+a2+a3)\n",
    "    return  Qd\n",
    "\n",
    "\n",
    "# find hcrit values\n",
    "hcrit=[]\n",
    "for i in range(N):\n",
    "    def fun(z):\n",
    "        fric = Qfric(z, i)\n",
    "        dam = Qdam(z, i)\n",
    "        return fric-dam\n",
    "    hcrit.append(root(fun, h_u[i]).x[0])\n",
    "hcrit = tuple(hcrit)  #make immutable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining $\\mathbf{\\tilde{Q}(\\mathbf{h})}$ and $\\mathbf{\\tilde{V}(\\mathbf{h})}$ properly. Note these are not vector valued functions, instead are a family of functions indexed by segment number $i$. See writeup for explanation of functions used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Qfun(h, i):\n",
    "    if h<max(hcrit[i], h_l[i]):\n",
    "        return  Qfric(h, i)\n",
    "    else:\n",
    "        return Qdam(h, i)\n",
    "    \n",
    "    \n",
    "def Vfun(h, i):\n",
    "    hstr = (Qfun(h,i) /w[i] /np.sqrt(S[i]))**(3/5)  #hstream downstream flow\n",
    "    if h < hstr + S[i]*l[i]/cst_beta:\n",
    "        return w[i]*l[i]*hstr + cst_lambda[i]*0.5*cst_beta*w[i]* max(0, h-hstr)**2 / S[i]\n",
    "    else:\n",
    "        return w[i]*l[i]*( h - S[i]*l[i]/cst_beta + cst_lambda[i]/2*S[i]*l[i]/cst_beta)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an approximation for $\\mathbf{\\tilde{Q}(\\mathbf{V})}$ - note $\\mathbf{\\tilde{V}(\\mathbf{h})}$ is made to be monotonic, this comes from having to invert it. This corresponds to  $min\\circ\\mathbf{\\tilde{V}^{-1}}$, as the inverse may be a multifunction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# approximate V(h)\n",
    "Vapprox = np.zeros((N, 100))\n",
    "for i in range(N):\n",
    "    runmax=0  #for monotonicity\n",
    "    for j, h in enumerate(np.linspace(0, 20, 100)):\n",
    "        runmax = max(runmax, Vfun(h, i))\n",
    "        Vapprox[i, j] = runmax\n",
    "        \n",
    "# approximate Q(h)\n",
    "Qapprox = np.zeros((N,100))\n",
    "for i in range(N):\n",
    "    for j, h in enumerate(np.linspace(0, 20, 100)):\n",
    "        Qapprox[i,j] = Qfun(h,i)\n",
    "\n",
    "# interpolate using the above approximations\n",
    "@jit(nopython=True)\n",
    "def Qvals(V):\n",
    "    Q = np.zeros((N,1))\n",
    "    for i in range(N):\n",
    "        Q[i,0] = np.interp(V[i], Vapprox[i,:], Qapprox[i,:])\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the derivative $D$ at a point, using the above function to find $\\mathbf{Q}$ given $\\mathbf{V}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def derivative(t, V):\n",
    "    #inflow\n",
    "    q = np.zeros((N,1))\n",
    "    q[:,0] = rainfun(t*cst_t)/cst_Q\n",
    "    #working out Q:\n",
    "    Q = Qvals(V)\n",
    "    #dV/dt\n",
    "    D = Adj.T.dot(Q) - Q  + q\n",
    "    return list(D.flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is not a stiff problem, I'm using the standard IVP solver, with a Runge-Kutta method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total time taken is 625.529208 seconds.\n"
     ]
    }
   ],
   "source": [
    "initial = [0]*(N)\n",
    "# derivative2 will only use the t=0 inflow to make a suitable baseflow.\n",
    "def derivative2(t, V):\n",
    "    return derivative(0, V)\n",
    "sol = solve_ivp(derivative2, (0,60*60/cst_t), initial, atol=1e-3)\n",
    "initial = sol.y[:,-1]\n",
    "\n",
    "\n",
    "T = (end-start).total_seconds() / cst_t\n",
    "startTime = datetime.now()\n",
    "sol = solve_ivp(derivative, (0,T), initial, t_eval=np.linspace(0,T,100) , atol=1e-3, method='RK23')\n",
    "print('The total time taken is ' + str((datetime.now()-startTime).total_seconds())+' seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most useful output are flow values. These can be calculated from Qfun defined above. I'm saving the flow values to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this, populate an empty dataframe of the right shape\n",
    "\n",
    "def qfunexp(V, i):\n",
    "    return np.interp(V, Vapprox[i,:], Qapprox[i,:])\n",
    "\n",
    "qoutput = pd.DataFrame(sol.y.copy().T, index=pd.date_range(start, end, 100))\n",
    "for i, col in enumerate(qoutput.columns):\n",
    "    qoutput[col] = qoutput[col].apply(lambda x: qfunexp(x, i)*cst_Q)\n",
    "qoutput.to_csv('data/numerical_flow_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, I'll output data about how filled each dam is - this is to help visualising the solution. Here I'll calculate how high the segment is in comparison to the impacting dam surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dam_df = pd.DataFrame(sol.y[dams].copy().T, index = pd.date_range(start, end, 100), columns=dams)\n",
    "for dam in dam_df.columns:\n",
    "    dam_df[dam] = dam_df[dam].apply(lambda x: (x>df.h_l[dam]) * min(1, (x-df.h_l[dam])/(df.h_u[dam]-df.h_l[dam]) ))\n",
    "dam_df.to_csv('data/numerical_dam_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
